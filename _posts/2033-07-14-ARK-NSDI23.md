---
title: 'ARK: GPU-driven Code Execution for Distributed Deep Learning'
date: 2023-08-13
permalink: /posts/2023/08/ARK/
tags:
  - 大模型
  - 分布式训练
  - GPU
---

### 概述：
通过让GPU运行代码并在没有CPU干预的情况下自主处理通信事件，克服了大型深度学习工作负载的GPU通信开销。


### 背景
##### 当前AI系统在规模上的特点
* 不断增大的模型size（超过10万亿的参数）；
* 使用更多的GPU协同训练；
* GPU间的通信成为训练的关键组成部分。

##### 通信开销：数据面和控制面
1. 小数据传输（小至几十KB）：
     
     * 模型架构；
     * 多阶段的集合通信；
     * 大规模：更多的阶段，更小的数据传输。

这意味着控制面开销增大：小数据传输中的事件处理（event handling）。

事件处理包括发送数据完成信号处理以及启动接下来的GPU任务。

2. 计算和通信重叠
   
    * 在数据并行和流水线并行中都存在；
    * IO对并行计算的干扰：如NCCL使用GPU线程进行数据IO，因此相比于没有overlapping，overlapping时吞吐量下降。

### 已有系统概述
* 已有的系统只就上述一方面进行优化。
* 将已有系统分为两种类型：
    * CPU控制的通信和GPU控制的通信：在CPU还是GPU上处理通信事件。

##### CPU-controlled
CPU线程轮询，以便知道GPU数据准备是否完成可以发送数据，如果数据准备好了，CPU会初始化GPU中的DMA引擎（可以通过调用cudaMemcpy）。然后DMA将数据copy到目标GPU中。这种方式通过io卸载（卸载至硬件DMA引擎）降低IO开销（数据面开销）。但是CPU的介入引入了额外的开销。

##### GPU-controlled
（如nccl）GPU会创建映射到目标GPU的memory map。数据准备完成后，GPU线程将数据拷贝到mmap中，进而数据会传输到目标GPU的内存中。
这种方式会取得一个低延迟，因为它没有使用CPU。
但是由于使用GPU线程进行数据copy，它仍然对GPU引入了IO负载。

### ARK
##### 两个关键设计
* GPU-controlled DMA：让GPU线程来直接初始化DMA。好处是一方面控制平面位于GPU上，没有了CPU的干预，更快的事件处理。另一方面，通过I/O卸载至DMA，减小I/O负载。
    * GPU线程无需复制数据；
    * 遗憾的是目前的商用GPU硬件不支持该能力：当前DMA引擎只能由CPU初始化；
    * 软件实现：GPU线程调用软件DMA引擎来对DMA进行初始化；
    * 硬件实现：同FPGA上实现的外部硬件DMA引擎。因为无需转发GPU的DMA请求，其效率更高。同时比起使用GPU上的DMA其展示了更高的吞吐量因为实现了并行多DMA copy，使PCIe饱和。
* GPU自主执行控制：GPU自行执行所有任务不需要外部的控制信号，无论是计算还是通信。在一个GPU内核中（loop kernel）有着所有GPU任务。具备快速的事件处理和高效的计算能力。
    * 输入是一个描述模型的运行图；
    * 分析这个图，生成一个GPU loop kernel；
    * 研究GPU所有必要的计算操作和通信操作。由这些操作可以最终组成一个深度学习模型。
    * 所有的GPU任务定义在一个gpu kernel中，最终我们能够全局优化通信和计算。
    * 传统的CPU驱动：调度若干CTA组成SM，并行计算；
    * 本文中的vCTAs：每个SM中仅有一个CTA，一个CTA中包含若干个VCTAs，因此能够通过代码生成以及添加代码片段进行调度




##### 评估

